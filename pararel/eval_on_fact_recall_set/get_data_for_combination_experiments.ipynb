{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798e4b91",
   "metadata": {},
   "source": [
    "# Get data for combination experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a674537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6651e6",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c4d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEFOLDER = \"/cephyr/users/lovhag/Alvis/projects/rome/data/prediction_mech_comb_experiments\"\n",
    "MODEL_NAME = \"llama2_7B\" # \"llama2_7B\" # \"gpt2_xl\"\n",
    "\n",
    "# for all configs, both settings with maximally confident and maximally unconfident samples are checked\n",
    "# gives number of samples per category\n",
    "SINGLETON_CONFIGS = {\n",
    "           \"single_prompt_bias\": {\"prompt_bias\": 1,\n",
    "                                  \"person_name_bias\": 0,\n",
    "                                  \"exact_recall\": 0,\n",
    "                                  \"guesswork\": 0,\n",
    "                                  \"generic\": 0\n",
    "                                             },\n",
    "           \"single_name_bias\": {\"prompt_bias\": 0,\n",
    "                                \"person_name_bias\": 1,\n",
    "                                \"exact_recall\": 0,\n",
    "                                \"guesswork\": 0,\n",
    "                                \"generic\": 0\n",
    "                               },\n",
    "           \"single_exact_recall\": {\"prompt_bias\": 0,\n",
    "                                   \"person_name_bias\": 0,\n",
    "                                   \"exact_recall\": 1,\n",
    "                                   \"guesswork\": 0 ,\n",
    "                                   \"generic\": 0\n",
    "                                  },\n",
    "           \"single_guesswork\": {\"prompt_bias\": 0,\n",
    "                                \"person_name_bias\": 0,\n",
    "                                \"exact_recall\": 0,\n",
    "                                \"guesswork\": 1,\n",
    "                                \"generic\": 0\n",
    "                               },\n",
    "           \"single_generic\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 1\n",
    "                             },\n",
    "           \"100_prompt_bias\": {\"prompt_bias\": 100,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"100_name_bias\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 100,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"100_exact_recall\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 100,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"100_guesswork\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 100,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"100_generic\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 100\n",
    "                         },\n",
    "           \"1000_prompt_bias\": {\"prompt_bias\": 1000, # unconfident/confident split doesn't matter here\n",
    "                              \"person_name_bias\": 0, # always takes _all_ samples\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"1000_name_bias\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 1000,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"1000_exact_recall\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 1000,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"1000_guesswork\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 1000,\n",
    "                              \"generic\": 0\n",
    "                             },\n",
    "           \"1000_generic\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 1000\n",
    "                         },\n",
    "          }\n",
    "\n",
    "# always 1000 samples for these, so give proportions\n",
    "COMPOSITION_CONFIGS = {\"50_exact_50_biased\": {\"prompt_bias\": 0.25,\n",
    "                              \"person_name_bias\": 0.25,\n",
    "                              \"exact_recall\": 0.5,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"75_exact_25_biased\": {\"prompt_bias\": 0.125,\n",
    "                              \"person_name_bias\": 0.125,\n",
    "                              \"exact_recall\": 0.75,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"25_exact_75_biased\": {\"prompt_bias\": 0.375,\n",
    "                              \"person_name_bias\": 0.375,\n",
    "                              \"exact_recall\": 0.25,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"45_exact_45_biased_10_guess\": {\"prompt_bias\": 0.225,\n",
    "                              \"person_name_bias\": 0.225,\n",
    "                              \"exact_recall\": 0.45,\n",
    "                              \"guesswork\": 0.1,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"40_exact_40_biased_20_guess\": {\"prompt_bias\": 0.2,\n",
    "                              \"person_name_bias\": 0.2,\n",
    "                              \"exact_recall\": 0.4,\n",
    "                              \"guesswork\": 0.2,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"25_exact_25_biased_50_guess\": {\"prompt_bias\": 0.125,\n",
    "                              \"person_name_bias\": 0.125,\n",
    "                              \"exact_recall\": 0.25,\n",
    "                              \"guesswork\": 0.5,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"45_exact_45_biased_10_generic\": {\"prompt_bias\": 0.225,\n",
    "                              \"person_name_bias\": 0.225,\n",
    "                              \"exact_recall\": 0.45,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0.1\n",
    "                         },\n",
    "                       \"50_exact_50_guess\": {\"prompt_bias\": 0,\n",
    "                              \"person_name_bias\": 0,\n",
    "                              \"exact_recall\": 0.5,\n",
    "                              \"guesswork\": 0.5,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                       \"100_biased\": {\"prompt_bias\": 0.5,\n",
    "                              \"person_name_bias\": 0.5,\n",
    "                              \"exact_recall\": 0,\n",
    "                              \"guesswork\": 0,\n",
    "                              \"generic\": 0\n",
    "                         },\n",
    "                      }\n",
    "for val in COMPOSITION_CONFIGS.values():\n",
    "    assert sum(val.values())==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae42c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS = {\"gpt2_xl\": {\"exact_recall\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/gpt2-xl/1000_exact.json\",\n",
    "             \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/gpt2-xl/causal_trace_2377617/cases\",\n",
    "             \"filename_template\": \"knowledge_{}_mlp.npz\" \n",
    "              },\n",
    "              \"prompt_bias\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/prompt_bias_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/prompt_bias_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              \"person_name_bias\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/person_name_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/person_name_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              \"guesswork\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/gpt2-xl/1000_guesswork.json\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/gpt2-xl/causal_trace_guesswork_2388522/cases\",\n",
    "              \"filename_template\": \"knowledge_{}_mlp.npz\"\n",
    "              },\n",
    "              \"generic\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/generic_samples/generic_samples.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/generic_samples/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              }          \n",
    "            },\n",
    "            \"llama2_7B\": {\"exact_recall\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_sensitivity_recall_eval_sets/llama2_7B/1000_exact.jsonl\",\n",
    "             \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/llama2_7B/causal_trace_exact_2398046/cases\",\n",
    "             \"filename_template\": \"{}_candidate_mlp.npz\" \n",
    "              },\n",
    "              \"prompt_bias\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/prompt_bias_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/prompt_bias_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              \"person_name_bias\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/person_name_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/person_name_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              \"guesswork\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_sensitivity_recall_eval_sets/llama2_7B/1000_guesswork.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/llama2_7B/causal_trace_guesswork_2398048/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              \"generic\": {\"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/generic_samples/generic_samples.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/generic_samples/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              }\n",
    "             },\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec9d1b4",
   "metadata": {},
   "source": [
    "## Data generation for singleton configs\n",
    "Sampled for both most confident and most unconfident samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda0ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_answer_p(row):\n",
    "    answer_ix = row.answers.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a7936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, config in SINGLETON_CONFIGS.items():\n",
    "    for d_name, num_samples in config.items():\n",
    "        if num_samples > 0:\n",
    "            src_datainfo = DATASETS[MODEL_NAME][d_name]\n",
    "            src_dataset = pd.read_json(src_datainfo[\"queries_file\"], lines=src_datainfo[\"queries_file\"].endswith(\"jsonl\"))\n",
    "            # add necessary metadata\n",
    "            src_dataset[\"type\"] = d_name\n",
    "            src_dataset[\"CT_results_dir\"] = src_datainfo[\"CT_results_dir\"]\n",
    "            src_dataset[\"filename_template\"] = src_datainfo[\"filename_template\"]\n",
    "            \n",
    "            # find probability value column\n",
    "            if \"p_answers\" in src_dataset.columns and type(src_dataset.p_answers.iloc[0]) is not list:\n",
    "                p_col = \"p_answers\"\n",
    "            elif \"candidate_p\" in src_dataset.columns:\n",
    "                p_col = \"candidate_p\"\n",
    "            elif \"probability\" in src_dataset.columns:\n",
    "                p_col = \"probability\"\n",
    "            else:\n",
    "                raise ValueError(\"Could not find a probability column\")\n",
    "            \n",
    "            # save data splits\n",
    "            # confident split\n",
    "            filename = os.path.join(SAVEFOLDER, f\"singleton/{MODEL_NAME}/{key}_confident.jsonl\")\n",
    "            src_dataset.sort_values(p_col, ascending=False).iloc[:num_samples].to_json(filename, orient=\"records\", lines=True)\n",
    "            # unconfident split\n",
    "            filename = os.path.join(SAVEFOLDER, f\"singleton/{MODEL_NAME}/{key}_unconfident.jsonl\")\n",
    "            src_dataset.sort_values(p_col).iloc[:num_samples].to_json(filename, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740d713d",
   "metadata": {},
   "source": [
    "## Data generation for combination configs\n",
    "Always 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b63d0510",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "\n",
    "part_info = {\"biased\": [\"prompt_bias\", \"person_name_bias\"],\n",
    "             \"exact\": [\"exact_recall\"],\n",
    "             \"guess\": [\"guesswork\"],\n",
    "             \"generic\": [\"generic\"]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ee2c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, config in COMPOSITION_CONFIGS.items():\n",
    "    data = pd.DataFrame()\n",
    "    for d_name, prop in config.items():\n",
    "        if prop > 0:\n",
    "            src_datainfo = DATASETS[MODEL_NAME][d_name]\n",
    "            src_dataset = pd.read_json(src_datainfo[\"queries_file\"], lines=src_datainfo[\"queries_file\"].endswith(\"jsonl\"))\n",
    "            src_dataset = src_dataset.sample(int(num_samples*prop), random_state=42)\n",
    "            \n",
    "            # add necessary metadata\n",
    "            src_dataset[\"type\"] = d_name\n",
    "            src_dataset[\"CT_results_dir\"] = src_datainfo[\"CT_results_dir\"]\n",
    "            src_dataset[\"filename_template\"] = src_datainfo[\"filename_template\"]\n",
    "            \n",
    "            data = pd.concat((data, src_dataset), ignore_index=True)\n",
    "            \n",
    "    # save data\n",
    "    filename = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{key}.jsonl\")\n",
    "    data.to_json(filename, orient=\"records\", lines=True)\n",
    "    \n",
    "    # save data parts\n",
    "    for part_name, d_names in part_info.items():\n",
    "        share_num = int(sum([config[d_name] for d_name in d_names])*100)\n",
    "        if share_num > 0:\n",
    "            part_filename = f\"{share_num}_{part_name}.jsonl\"\n",
    "            part_filepath = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{part_filename}\")\n",
    "            data[data.type.isin(d_names)].to_json(part_filepath, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b59c021",
   "metadata": {},
   "source": [
    "Also with min and max confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47360746",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, config in COMPOSITION_CONFIGS.items():\n",
    "    conf_data = pd.DataFrame()\n",
    "    unconf_data = pd.DataFrame()\n",
    "    for d_name, prop in config.items():\n",
    "        if prop > 0:\n",
    "            src_datainfo = DATASETS[MODEL_NAME][d_name]\n",
    "            src_dataset = pd.read_json(src_datainfo[\"queries_file\"], lines=src_datainfo[\"queries_file\"].endswith(\"jsonl\"))\n",
    "            # add necessary metadata\n",
    "            src_dataset[\"type\"] = d_name\n",
    "            src_dataset[\"CT_results_dir\"] = src_datainfo[\"CT_results_dir\"]\n",
    "            src_dataset[\"filename_template\"] = src_datainfo[\"filename_template\"]\n",
    "            \n",
    "            # find probability value column\n",
    "            if \"p_answers\" in src_dataset.columns and type(src_dataset.p_answers.iloc[0]) is not list:\n",
    "                p_col = \"p_answers\"\n",
    "            elif \"candidate_p\" in src_dataset.columns:\n",
    "                p_col = \"candidate_p\"\n",
    "            elif \"probability\" in src_dataset.columns:\n",
    "                p_col = \"probability\"\n",
    "            else:\n",
    "                raise ValueError(\"Could not find a probability column\")\n",
    "            \n",
    "            num_part_samples = int(num_samples*prop)\n",
    "            conf_data = pd.concat((conf_data, src_dataset.sort_values(p_col, ascending=False).iloc[:num_part_samples]), ignore_index=True)\n",
    "            unconf_data = pd.concat((unconf_data, src_dataset.sort_values(p_col).iloc[:num_part_samples]), ignore_index=True)\n",
    "            \n",
    "    # save data\n",
    "    conf_filename = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{key}_confident.jsonl\")\n",
    "    conf_data.to_json(conf_filename, orient=\"records\", lines=True)\n",
    "    unconf_filename = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{key}_unconfident.jsonl\")\n",
    "    unconf_data.to_json(unconf_filename, orient=\"records\", lines=True)\n",
    "    \n",
    "    # save data parts\n",
    "    for part_name, d_names in part_info.items():\n",
    "        share_num = int(sum([config[d_name] for d_name in d_names])*100)\n",
    "        if share_num > 0:\n",
    "            # confident\n",
    "            part_filename = f\"{share_num}_{part_name}_confident.jsonl\"\n",
    "            part_filepath = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{part_filename}\")\n",
    "            conf_data[conf_data.type.isin(d_names)].to_json(part_filepath, orient=\"records\", lines=True)\n",
    "            \n",
    "            # unconfident\n",
    "            part_filename = f\"{share_num}_{part_name}_unconfident.jsonl\"\n",
    "            part_filepath = os.path.join(SAVEFOLDER, f\"combined/{MODEL_NAME}/{part_filename}\")\n",
    "            unconf_data[unconf_data.type.isin(d_names)].to_json(part_filepath, orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
