{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798e4b91",
   "metadata": {},
   "source": [
    "# Get combined mechanisms data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a674537",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6651e6",
   "metadata": {},
   "source": [
    "## Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3c4d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"llama2_7B\" # \"gpt2-xl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae42c4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"gpt2-xl\": [{\"name\": \"string_match\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/string_match_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/string_match_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              {\"name\": \"prompt_bias\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/prompt_bias_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/prompt_bias_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              {\"name\": \"person_name_bias\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/person_name_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/gpt2_xl/synthetic_data/person_name_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              }\n",
    "             ],\n",
    "            \"llama2_7B\": [{\"name\": \"string_match\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/string_match_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/string_match_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              {\"name\": \"prompt_bias\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/prompt_bias_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/prompt_bias_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "              {\"name\": \"person_name_bias\",\n",
    "              \"queries_file\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/person_name_bias.jsonl\",\n",
    "              \"CT_results_dir\": \"/cephyr/users/lovhag/Alvis/projects/fact-recall-detection/data/CT_results/llama2_7B/synthetic_data/person_name_bias/cases\",\n",
    "              \"filename_template\": \"{}_candidate_mlp.npz\"\n",
    "              },\n",
    "             ],\n",
    "            }\n",
    "\n",
    "NUM_SAMPLES = {\"gpt2-xl\": {\"prompt_bias\": 483,\n",
    "                           \"person_name_bias\": 483,\n",
    "                           \"string_match\": 34\n",
    "                          },\n",
    "               \"llama2_7B\": {\"prompt_bias\": 483,\n",
    "                             \"person_name_bias\": 483,\n",
    "                             \"string_match\": 34 # we actually have 557 samples here\n",
    "                            }\n",
    "              }\n",
    "\n",
    "assert sum(NUM_SAMPLES[MODEL_NAME].values()) == 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424d6f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicate_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>template</th>\n",
       "      <th>prompt</th>\n",
       "      <th>answers</th>\n",
       "      <th>p_answers</th>\n",
       "      <th>non_trivial</th>\n",
       "      <th>trivial</th>\n",
       "      <th>source</th>\n",
       "      <th>answers_for_PB_He</th>\n",
       "      <th>...</th>\n",
       "      <th>confident_flag</th>\n",
       "      <th>prompt_bias</th>\n",
       "      <th>answers_for_PB_It</th>\n",
       "      <th>answers_for_PB_The_city</th>\n",
       "      <th>answers_for_PB_The_organisation</th>\n",
       "      <th>string_match</th>\n",
       "      <th>person_name</th>\n",
       "      <th>type</th>\n",
       "      <th>CT_results_dir</th>\n",
       "      <th>filename_template</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1376</td>\n",
       "      <td>Corada</td>\n",
       "      <td>[X], that is the capital city of [Y]</td>\n",
       "      <td>Corada, that is the capital city of</td>\n",
       "      <td>[the, Cor, C]</td>\n",
       "      <td>[0.3585913181, 0.028969476, 0.0135875521]</td>\n",
       "      <td>[Cor, C]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>Town_Central_America</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[the, South, Italy, New, Japan, North, H, Fran...</td>\n",
       "      <td>[the, South, India, T, U, K, Raj, P, Gu, a]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>string_match</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P27</td>\n",
       "      <td>Vanathe Bronzemoon</td>\n",
       "      <td>[X] is a citizen of [Y]</td>\n",
       "      <td>Vanathe Bronzemoon is a citizen of</td>\n",
       "      <td>[the, The, T]</td>\n",
       "      <td>[0.29929867390000003, 0.0284785964, 0.0133922771]</td>\n",
       "      <td>[The, T]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>DND_human_female</td>\n",
       "      <td>[the, a, India, Canada, both, France, United, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>string_match</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1376</td>\n",
       "      <td>Selizar</td>\n",
       "      <td>[X], that is the capital city of [Y]</td>\n",
       "      <td>Selizar, that is the capital city of</td>\n",
       "      <td>[the, Sel, a]</td>\n",
       "      <td>[0.3476739824, 0.0453029387, 0.0138709573]</td>\n",
       "      <td>[Sel]</td>\n",
       "      <td>[the, a]</td>\n",
       "      <td>Town_Middle_Eastern</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[the, South, Italy, New, Japan, North, H, Fran...</td>\n",
       "      <td>[the, South, India, T, U, K, Raj, P, Gu, a]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>string_match</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1376</td>\n",
       "      <td>Marguly</td>\n",
       "      <td>[X] is the capital city of [Y]</td>\n",
       "      <td>Marguly is the capital city of</td>\n",
       "      <td>[the, Marg, a]</td>\n",
       "      <td>[0.38308918480000004, 0.0709039867, 0.01940537...</td>\n",
       "      <td>[Marg]</td>\n",
       "      <td>[the, a]</td>\n",
       "      <td>Town_Central_Asia</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[the, K, South, H, P, U, Gu, T, Raj, India]</td>\n",
       "      <td>[the, South, P, U, K, Gu, T, H, Raj, India]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>string_match</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1376</td>\n",
       "      <td>Walenseen</td>\n",
       "      <td>[X], the capital of [Y]</td>\n",
       "      <td>Walenseen, the capital of</td>\n",
       "      <td>[the, Wal, a]</td>\n",
       "      <td>[0.4047284424, 0.0514705144, 0.0194060858]</td>\n",
       "      <td>[Wal]</td>\n",
       "      <td>[the, a]</td>\n",
       "      <td>Town_West_Europe</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>[the, Italy, South, P, New, Catal, North, Sic,...</td>\n",
       "      <td>[the, South, K, T, P, H, U, a, S, Gu]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>string_match</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>P27</td>\n",
       "      <td>Ji Juem</td>\n",
       "      <td>[X] is a citizen of [Y]</td>\n",
       "      <td>Ji Juem is a citizen of</td>\n",
       "      <td>[the, China, Taiwan]</td>\n",
       "      <td>[0.47464603190000004, 0.1659510136, 0.0276172794]</td>\n",
       "      <td>[China, Taiwan]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>DND_human_male</td>\n",
       "      <td>[the, a, India, Canada, both, France, United, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>person_name_bias</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>P27</td>\n",
       "      <td>Khrebtova Tasha Vladislavovna</td>\n",
       "      <td>[X] holds a citizenship of [Y]</td>\n",
       "      <td>Khrebtova Tasha Vladislavovna holds a citizens...</td>\n",
       "      <td>[the, Ukraine, Russia]</td>\n",
       "      <td>[0.4659574032, 0.1603333503, 0.11799981450000001]</td>\n",
       "      <td>[Ukraine, Russia]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>Russian</td>\n",
       "      <td>[the, United, Canada, Germany, France, USA, Au...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>person_name_bias</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>P19</td>\n",
       "      <td>Pierrette Pasteur</td>\n",
       "      <td>[X] was originally from [Y]</td>\n",
       "      <td>Pierrette Pasteur was originally from</td>\n",
       "      <td>[France, the, Montreal]</td>\n",
       "      <td>[0.1137229651, 0.1018302292, 0.047013603200000...</td>\n",
       "      <td>[France, Montreal]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>French</td>\n",
       "      <td>[the, a, New, B, C, England, St, South, H, S]</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>person_name_bias</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>P19</td>\n",
       "      <td>Claudine Seyrès</td>\n",
       "      <td>[X] originates from [Y]</td>\n",
       "      <td>Claudine Seyrès originates from</td>\n",
       "      <td>[a, the, France]</td>\n",
       "      <td>[0.22212101520000002, 0.20952263470000002, 0.0...</td>\n",
       "      <td>[France]</td>\n",
       "      <td>[a, the]</td>\n",
       "      <td>French</td>\n",
       "      <td>[the, a, an, New, South, B, T, England, , K]</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>person_name_bias</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>P27</td>\n",
       "      <td>Lancd Ravestul</td>\n",
       "      <td>[X] holds a citizenship of [Y]</td>\n",
       "      <td>Lancd Ravestul holds a citizenship of</td>\n",
       "      <td>[the, Roman, France]</td>\n",
       "      <td>[0.23334224520000002, 0.038189705500000004, 0....</td>\n",
       "      <td>[Roman, France]</td>\n",
       "      <td>[the]</td>\n",
       "      <td>DND_human_female</td>\n",
       "      <td>[the, United, Canada, Germany, France, USA, Au...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>person_name_bias</td>\n",
       "      <td>/cephyr/users/lovhag/Alvis/projects/fact-recal...</td>\n",
       "      <td>{}_candidate_mlp.npz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicate_id                        subject  \\\n",
       "0          P1376                         Corada   \n",
       "1            P27             Vanathe Bronzemoon   \n",
       "2          P1376                        Selizar   \n",
       "3          P1376                        Marguly   \n",
       "4          P1376                      Walenseen   \n",
       "..           ...                            ...   \n",
       "995          P27                        Ji Juem   \n",
       "996          P27  Khrebtova Tasha Vladislavovna   \n",
       "997          P19              Pierrette Pasteur   \n",
       "998          P19                Claudine Seyrès   \n",
       "999          P27                 Lancd Ravestul   \n",
       "\n",
       "                                 template  \\\n",
       "0    [X], that is the capital city of [Y]   \n",
       "1                 [X] is a citizen of [Y]   \n",
       "2    [X], that is the capital city of [Y]   \n",
       "3          [X] is the capital city of [Y]   \n",
       "4                 [X], the capital of [Y]   \n",
       "..                                    ...   \n",
       "995               [X] is a citizen of [Y]   \n",
       "996        [X] holds a citizenship of [Y]   \n",
       "997           [X] was originally from [Y]   \n",
       "998               [X] originates from [Y]   \n",
       "999        [X] holds a citizenship of [Y]   \n",
       "\n",
       "                                                prompt  \\\n",
       "0                  Corada, that is the capital city of   \n",
       "1                   Vanathe Bronzemoon is a citizen of   \n",
       "2                 Selizar, that is the capital city of   \n",
       "3                       Marguly is the capital city of   \n",
       "4                            Walenseen, the capital of   \n",
       "..                                                 ...   \n",
       "995                            Ji Juem is a citizen of   \n",
       "996  Khrebtova Tasha Vladislavovna holds a citizens...   \n",
       "997              Pierrette Pasteur was originally from   \n",
       "998                    Claudine Seyrès originates from   \n",
       "999              Lancd Ravestul holds a citizenship of   \n",
       "\n",
       "                     answers  \\\n",
       "0              [the, Cor, C]   \n",
       "1              [the, The, T]   \n",
       "2              [the, Sel, a]   \n",
       "3             [the, Marg, a]   \n",
       "4              [the, Wal, a]   \n",
       "..                       ...   \n",
       "995     [the, China, Taiwan]   \n",
       "996   [the, Ukraine, Russia]   \n",
       "997  [France, the, Montreal]   \n",
       "998         [a, the, France]   \n",
       "999     [the, Roman, France]   \n",
       "\n",
       "                                             p_answers         non_trivial  \\\n",
       "0            [0.3585913181, 0.028969476, 0.0135875521]            [Cor, C]   \n",
       "1    [0.29929867390000003, 0.0284785964, 0.0133922771]            [The, T]   \n",
       "2           [0.3476739824, 0.0453029387, 0.0138709573]               [Sel]   \n",
       "3    [0.38308918480000004, 0.0709039867, 0.01940537...              [Marg]   \n",
       "4           [0.4047284424, 0.0514705144, 0.0194060858]               [Wal]   \n",
       "..                                                 ...                 ...   \n",
       "995  [0.47464603190000004, 0.1659510136, 0.0276172794]     [China, Taiwan]   \n",
       "996  [0.4659574032, 0.1603333503, 0.11799981450000001]   [Ukraine, Russia]   \n",
       "997  [0.1137229651, 0.1018302292, 0.047013603200000...  [France, Montreal]   \n",
       "998  [0.22212101520000002, 0.20952263470000002, 0.0...            [France]   \n",
       "999  [0.23334224520000002, 0.038189705500000004, 0....     [Roman, France]   \n",
       "\n",
       "      trivial                source  \\\n",
       "0       [the]  Town_Central_America   \n",
       "1       [the]      DND_human_female   \n",
       "2    [the, a]   Town_Middle_Eastern   \n",
       "3    [the, a]     Town_Central_Asia   \n",
       "4    [the, a]      Town_West_Europe   \n",
       "..        ...                   ...   \n",
       "995     [the]        DND_human_male   \n",
       "996     [the]               Russian   \n",
       "997     [the]                French   \n",
       "998  [a, the]                French   \n",
       "999     [the]      DND_human_female   \n",
       "\n",
       "                                     answers_for_PB_He  ... confident_flag  \\\n",
       "0                                                 None  ...           True   \n",
       "1    [the, a, India, Canada, both, France, United, ...  ...           True   \n",
       "2                                                 None  ...           True   \n",
       "3                                                 None  ...           True   \n",
       "4                                                 None  ...           True   \n",
       "..                                                 ...  ...            ...   \n",
       "995  [the, a, India, Canada, both, France, United, ...  ...           True   \n",
       "996  [the, United, Canada, Germany, France, USA, Au...  ...           True   \n",
       "997      [the, a, New, B, C, England, St, South, H, S]  ...           True   \n",
       "998       [the, a, an, New, South, B, T, England, , K]  ...           True   \n",
       "999  [the, United, Canada, Germany, France, USA, Au...  ...           True   \n",
       "\n",
       "    prompt_bias                                  answers_for_PB_It  \\\n",
       "0         False  [the, South, Italy, New, Japan, North, H, Fran...   \n",
       "1         False                                               None   \n",
       "2         False  [the, South, Italy, New, Japan, North, H, Fran...   \n",
       "3         False        [the, K, South, H, P, U, Gu, T, Raj, India]   \n",
       "4         False  [the, Italy, South, P, New, Catal, North, Sic,...   \n",
       "..          ...                                                ...   \n",
       "995       False                                                NaN   \n",
       "996       False                                                NaN   \n",
       "997       False                                                NaN   \n",
       "998       False                                                NaN   \n",
       "999       False                                                NaN   \n",
       "\n",
       "                         answers_for_PB_The_city  \\\n",
       "0    [the, South, India, T, U, K, Raj, P, Gu, a]   \n",
       "1                                           None   \n",
       "2    [the, South, India, T, U, K, Raj, P, Gu, a]   \n",
       "3    [the, South, P, U, K, Gu, T, H, Raj, India]   \n",
       "4          [the, South, K, T, P, H, U, a, S, Gu]   \n",
       "..                                           ...   \n",
       "995                                          NaN   \n",
       "996                                          NaN   \n",
       "997                                          NaN   \n",
       "998                                          NaN   \n",
       "999                                          NaN   \n",
       "\n",
       "     answers_for_PB_The_organisation string_match person_name  \\\n",
       "0                                NaN         True       False   \n",
       "1                                NaN         True       False   \n",
       "2                                NaN         True       False   \n",
       "3                                NaN         True       False   \n",
       "4                                NaN         True       False   \n",
       "..                               ...          ...         ...   \n",
       "995                              NaN        False        True   \n",
       "996                              NaN        False        True   \n",
       "997                              NaN        False        True   \n",
       "998                              NaN        False        True   \n",
       "999                              NaN        False        True   \n",
       "\n",
       "                 type                                     CT_results_dir  \\\n",
       "0        string_match  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "1        string_match  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "2        string_match  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "3        string_match  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "4        string_match  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "..                ...                                                ...   \n",
       "995  person_name_bias  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "996  person_name_bias  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "997  person_name_bias  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "998  person_name_bias  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "999  person_name_bias  /cephyr/users/lovhag/Alvis/projects/fact-recal...   \n",
       "\n",
       "        filename_template  \n",
       "0    {}_candidate_mlp.npz  \n",
       "1    {}_candidate_mlp.npz  \n",
       "2    {}_candidate_mlp.npz  \n",
       "3    {}_candidate_mlp.npz  \n",
       "4    {}_candidate_mlp.npz  \n",
       "..                    ...  \n",
       "995  {}_candidate_mlp.npz  \n",
       "996  {}_candidate_mlp.npz  \n",
       "997  {}_candidate_mlp.npz  \n",
       "998  {}_candidate_mlp.npz  \n",
       "999  {}_candidate_mlp.npz  \n",
       "\n",
       "[1000 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "for dataset in datasets[MODEL_NAME]:\n",
    "    tmp_data = pd.read_json(dataset[\"queries_file\"], lines=dataset[\"queries_file\"].endswith(\"jsonl\")).sample(\n",
    "        NUM_SAMPLES[MODEL_NAME][dataset[\"name\"]], random_state=42)\n",
    "    tmp_data[\"type\"] = dataset[\"name\"]\n",
    "    tmp_data[\"CT_results_dir\"] = dataset[\"CT_results_dir\"]\n",
    "    tmp_data[\"filename_template\"] = dataset[\"filename_template\"]\n",
    "    data = pd.concat((data, tmp_data), ignore_index=True)\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "768ed036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prompt_bias         483\n",
       "person_name_bias    483\n",
       "string_match         34\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d97f8a",
   "metadata": {},
   "source": [
    "Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1af4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json(f\"/cephyr/users/lovhag/Alvis/projects/rome/data/eval_on_fact_recall_set/{MODEL_NAME}/1000_combined_bias_mechanisms.json\", orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
